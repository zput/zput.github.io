<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>redis总结 - Zput's blog</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=cache-control content="no-transform"><meta http-equiv=cache-control content="no-siteapp"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=author content="zput"><meta name=description content="Redis redis中有一个「核心的对象」叫做redisObject 是用来表示所有的key和value的，用redisObject结构体来表示Str"><meta name=keywords content="Hugo,theme,even"><meta name=generator content="Hugo 0.101.0 with theme even"><link rel=canonical href=http://zput.github.io/post/mrmk/redis/><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/manifest.json><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link href=/sass/main.min.fdb1035139209ff03fa34c28400ff54f04900828b7cafe0d2cfb1f48b70a2ffd.css rel=stylesheet><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin=anonymous><meta property="og:title" content="redis总结"><meta property="og:description" content="Redis redis中有一个「核心的对象」叫做redisObject 是用来表示所有的key和value的，用redisObject结构体来表示Str"><meta property="og:type" content="article"><meta property="og:url" content="http://zput.github.io/post/mrmk/redis/"><meta property="article:section" content="post"><meta itemprop=name content="redis总结"><meta itemprop=description content="Redis redis中有一个「核心的对象」叫做redisObject 是用来表示所有的key和value的，用redisObject结构体来表示Str"><meta itemprop=wordCount content="9301"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="redis总结"><meta name=twitter:description content="Redis redis中有一个「核心的对象」叫做redisObject 是用来表示所有的key和value的，用redisObject结构体来表示Str"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>Zput</a></div><div class=mobile-navbar-icon><span></span>
<span></span>
<span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><a href=/go-goroutine><li class=mobile-menu-item>go源码专栏</li></a><a href=/post/mrmk/><li class=mobile-menu-item>中间件专栏</li></a><a href=/post/cloud_native/><li class=mobile-menu-item>云原生专栏</li></a><a href=/post/postgraduate/><li class=mobile-menu-item>考研专栏</li></a><a href=/post/><li class=mobile-menu-item>时间线</li></a></ul></nav><div class=container id=mobile-panel><header id=header class=header><div class=logo-wrapper><a href=/ class=logo>Zput</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=/go-goroutine>go源码专栏</a></li><li class=menu-item><a class=menu-item-link href=/post/mrmk/>中间件专栏</a></li><li class=menu-item><a class=menu-item-link href=/post/cloud_native/>云原生专栏</a></li><li class=menu-item><a class=menu-item-link href=/post/postgraduate/>考研专栏</a></li><li class=menu-item><a class=menu-item-link href=/post/>时间线</a></li></ul></nav></header><main id=main class=main><div class=content-wrapper><div id=content class=content><article class=post><header class=post-header><h1 class=post-title>redis总结</h1><div class=post-meta><span class=post-time>0001-01-01</span></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>文章目录</h2><div class="post-toc-content always-active"><nav id=TableOfContents><ul><li><a href=#redis>Redis</a><ul><li><a href=#other>other</a></li></ul></li></ul></nav></div></div><div class=article-container><div class=post-content><h1 id=redis>Redis</h1><ul><li><p>redis中有一个「核心的对象」叫做redisObject</p><ul><li><img src=https://raw.githubusercontent.com/zput/myPicLib/master/zput.github.io/20210220112119.png alt=20210220112119><ul><li>是用来表示所有的key和value的，用redisObject结构体来表示String、Hash、List、Set、ZSet五种数据类型。</li><li>type表示属于哪种数据类型，encoding表示该数据的存储方式<ul><li><img src=https://raw.githubusercontent.com/zput/myPicLib/master/zput.github.io/20210220112710.png alt=20210220112710></li></ul></li></ul></li><li>String类型的数据结构存储方式有三种int、raw、embstr。<ul><li>int<ul><li>Redis中规定假如存储的是「整数型值」，比如set num 123这样的类型，就会使用 int的存储方式进行存储，在redisObject的「ptr属性」中就会保存该值。<img src=https://raw.githubusercontent.com/zput/myPicLib/master/zput.github.io/20210220104436.png alt=20210220104436></li></ul></li><li>raw: 字符串是一个字符串值并且长度大于32个字节<ul><li>使用SDS（simple dynamic string）方式进行存储</li><li>且encoding设置为raw</li></ul></li><li>embstr: 字符串长度小于等于32个字节<ul><li>使用SDS（simple dynamic string）方式进行存储</li><li>且encoding设置为embstr<ul><li>SDS（simple dynamic string）<ul><li>len保存了字符串的长度，</li><li>buf数组则是保存字符串的每一个字符元素。</li><li>free表示buf数组中未使用的字节数量</li><li><img src=https://raw.githubusercontent.com/zput/myPicLib/master/zput.github.io/20210220111805.png alt=Redsi中存储一个字符串Hello时><ul><li>c语言字符串与SDS对比:<ul><li>获取长度的时间复杂度为O(n) | 获取长度的时间复杂度为O(1)</li><li>不是二进制安全的 | 是二进制安全的</li><li>只能保存字符串 | 还可以保存二进制数据</li><li>n次增长字符串必然会带来n次的内存分配 | n次增长字符串内存分配的次数&lt;=n</li></ul></li></ul></li></ul></li></ul></li></ul></li></ul></li><li>hash<ul><li>ziplist: 一组连续的内存空间的使用，节省空间.<ul><li>编码的哈希对象使用压缩列表作为底层实现， <strong>每当有新的键值对要加入到哈希对象时， 程序会先将保存了键的压缩列表节点推入到压缩列表表尾， 然后再将保存了值的压缩列表节点推入到压缩列表表尾</strong></li><li><img src=https://raw.githubusercontent.com/zput/myPicLib/master/zput.github.io/20210220144824.png alt=20210220144824></li></ul></li><li>hashtable<ul><li>编码的哈希对象使用字典作为底层实现， 哈希对象中的每个键值对都使用一个字典键值对来保存：<ul><li>字典的每个键都是一个字符串对象， 对象中保存了键值对的键；</li><li>字典的每个值都是一个字符串对象， 对象中保存了键值对的值。</li></ul></li><li><img src=https://raw.githubusercontent.com/zput/myPicLib/master/zput.github.io/20210220145440.png alt=20210220145440><ul><li>Redis 的<strong>字典</strong>使用<strong>哈希表</strong>作为底层实现， 一个哈希表里面可以有<strong>多个哈希表节点</strong>， 而每个哈希表节点就保存了字典中的<strong>一个键值对</strong>。<ul><li>哈希表:<code>typedef struct dictht {</code></li><li>哈希表节点: <code>typedef struct dictEntry {</code></li><li>字典: <code>typedef struct dict {</code><ul><li>hash算法:<ul><li>使用字典设置的哈希函数，计算键 key 的哈希值<code>hash = dict->type->hashFunction(key);</code></li><li>使用哈希表的 sizemask 属性和哈希值，计算出索引值; 根据情况不同， ht<input checked disabled type=checkbox> 可以是 ht[0] 或者 ht[1]<code>index = hash & dict->ht[x].sizemask;</code></li></ul></li><li>解决键冲突: <strong>拉链法</strong><ul><li><img src=https://raw.githubusercontent.com/zput/myPicLib/master/zput.github.io/20210220152248.png alt=20210220152248></li></ul></li><li>hash rehash:<ul><li>一般情况下， 字典只使用<code>ht[0]</code>哈希表，<code>ht[1]</code>哈希表只会在对<code>ht[0]</code>哈希表进行 rehash 时使用。</li><li>除了<code>ht[1]</code>之外， 另一个和 rehash 有关的属性就是 rehashidx ： 它记录了 rehash 目前的进度， 如果目前没有在进行 rehash ， 那么它的值为 -1 。</li><li>步骤：<ul><li><ol><li>为字典的 ht[1] 哈希表分配空间， 这个哈希表的空间大小取决于要执行的操作，以及 ht[0] 当前包含的键值对数量（也即是ht[0].used 属性的值）：</li></ol><ul><li>如果执行的是扩展操作， 那么 ht[1] 的大小为第一个大于等于 ht[0].used * 2 的 2^n （2 的 n 次方幂）；</li><li>如果执行的是收缩操作， 那么 ht[1] 的大小为第一个大于等于 ht[0].used 的 2^n 。</li></ul></li><li><ol start=2><li>将保存在 ht[0] 中的所有键值对 rehash 到 ht[1] 上面： rehash 指的是重新计算键的哈希值和索引值， 然后将键值对放置到 ht[1] 哈希表的指定位置上。</li></ol></li><li><ol start=3><li>当 ht[0] 包含的所有键值对都迁移到了 ht[1] 之后 （ht[0] 变为空表）， 释放 ht[0] ， 将 ht[1] 设置为 ht[0] ， 并在 ht[1] 新创建一个空白哈希表， 为下一次 rehash 做准备。</li></ol></li></ul></li><li>当以下条件中的任意一个被满足时， 程序会自动开始对哈希表执行扩展操作：<ul><li>服务器目前没有在执行 BGSAVE 命令或者 BGREWRITEAOF 命令， 并且哈希表的负载因子大于等于 1 ；</li><li>服务器目前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令， 并且哈希表的负载因子大于等于 5 ；</li><li>负载因子: <code>负载因子 = 哈希表已保存节点数量 / 哈希表大小 ====> load_factor = ht[0].used / ht[0].size</code></li></ul></li><li>哈希表渐进式 rehash 的详细步骤：<ul><li><ol><li>为 ht[1] 分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表。</li></ol></li><li><ol start=2><li>在字典中维持一个索引计数器变量 <code>rehashidx</code> ， 并将它的值设置为 0(<strong>当没有rehash的时候，它是-1</strong>) ， 表示 rehash 工作正式开始。</li></ol></li><li><ol start=3><li>在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 ht[0] 哈希表在 <strong><code>rehashidx</code>(这个变量当前的index是多是，比如0,1,2&mldr;) 索引上的所有键值对 rehash 到 ht[1]</strong> ， 当 rehash 工作完成之后， 程序将<code>rehashidx</code>属性的值增一。</li></ol></li><li><ol start=4><li>随着字典操作的不断执行， 最终在某个时间点上， ht[0] 的所有键值对都会被 rehash 至 ht[1] ， 这时程序将 rehashidx 属性的值设为 -1 ， 表示 rehash 操作已完成。</li></ol></li></ul></li></ul></li></ul></li></ul></li></ul></li></ul></li><li>编码转换<ul><li>当哈希对象可以<strong>同时满足</strong>以下两个条件时， 哈希对象使用 ziplist 编码：<ul><li>哈希对象保存的所有键值对的键和值的字符串长度都小于 64 字节；</li><li>哈希对象保存的键值对数量小于 512 个；<ul><li>这两个条件的上限值是可以修改的， 具体请看配置文件中关于 <code>hash-max-ziplist-value</code> 选项和 <code>hash-max-ziplist-entries</code> 选项的说明。</li></ul></li></ul></li><li>不能满足这两个条件的哈希对象需要使用 hashtable 编码。</li></ul></li></ul></li></ul></li><li><p>跳跃表 ( skiplist )</p><ul><li>what:<ul><li><p>是一个单向链表, 只是有些节点中维持多个指向其后节点的指针, 形成分层的结构，利用二分查找思想, 从而达到快速访问节点的目的。</p></li><li><p>空间复杂度:假设原始链表大小为n,那么第1层索引大约有n/2个节点，第2层有n/4个节点，依次类推，直到最后剩下2个节点，总数为 $\frac{n}{2}+\frac{n}{4}+\frac{n}{8}+&mldr;+8+4+2=n-2$, 因此O(n)</p></li><li><p>时间复杂度为$ O(\log n) $ ，根据上面的图解，也不难理解，其实插入和删除都是在一次查找过程中实现的。插入和删除的复杂度也是 $ O(\log n) $</p></li><li><p>Redis使用跳跃表作为有序集合键的底层实现之一，如果一个有序集合包含的元素数量比较多，又或者有序集合中元素的成员 ( member ) 是比较长的字符串时，Redis 就会使用跳跃表来作为有序集合键的底层实现。</p></li></ul></li><li>why:<ul><li>首先，因为 zset 要支持随机的插入和删除，所以它 不宜使用数组来实现，关于排序问题，我们也很容易就想到 红黑树/ 平衡树 这样的树形结构，为什么 Redis 不使用这样一些结构呢？<ul><li>性能考虑： 在高并发的情况下，树形结构需要执行一些类似于 rebalance 这样的可能涉及整棵树的操作，相对来说跳跃表的变化只涉及局部 (下面详细说)；</li><li>实现考虑： 在复杂度与红黑树相同的情况下，跳跃表实现起来更简单，看起来也更加直观；</li></ul></li></ul></li><li>how:<ul><li><img src=https://raw.githubusercontent.com/zput/myPicLib/master/zput.github.io/20210220203234.png alt=20210220203234></li><li><a href=https://lotabout.me/2018/skip-list/#%E8%B7%B3%E8%A1%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3>https://lotabout.me/2018/skip-list/#%E8%B7%B3%E8%A1%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3</a></li></ul></li></ul></li></ul><h2 id=other>other</h2><ul><li>SDS与c语言字符串对比:<ul><li>Redis使用SDS作为存储字符串的类型肯定是有自己的优势，SDS与c语言的字符串相比，SDS对c语言的字符串做了自己的设计和优化，具体优势有以下几点：<ul><li><ol><li>c语言中的字符串并不会记录自己的长度，因此「每次获取字符串的长度都会遍历得到，时间的复杂度是O(n)」，而Redis中获取字符串只要读取len的值就可，时间复杂度变为O(1)。</li></ol></li><li><ol start=2><li>「c语言」中两个字符串拼接，若是没有分配足够长度的内存空间就「会出现缓冲区溢出的情况」；而「SDS」会先根据len属性判断空间是否满足要求，若是空间不够，就会进行相应的空间扩展，所以「不会出现缓冲区溢出的情况」。</li></ol></li><li><ol start=3><li>SDS还提供「空间预分配」和「惰性空间释放」两种策略。</li></ol><ul><li>在为字符串分配空间时，分配的空间比实际要多，这样就能「减少连续的执行字符串增长带来内存重新分配的次数」。<ul><li>具体的空间预分配原则是：(这里说的是在保证字符串的长度后，还需要预先分配额外的空间大小)<ul><li><strong>「当修改字符串后的长度len小于1MB(字符串的长度小于1MB)，就会预分配额外和len一样长度的空间，即len=free；若是len大于1MB，free分配额外的空间大小就为1MB」。</strong></li></ul></li></ul></li><li>当字符串被缩短的时候，SDS也不会立即回收不适用的空间，而是通过free属性将不使用的空间记录下来，等后面使用的时候再释放。</li></ul></li><li><ol start=4><li>SDS是<strong>二进制安全的</strong>，除了可以<strong>储存字符串以外还可以储存二进制文件</strong>（如图片、音频，视频等文件的二进制数据）；而c语言中的<code>字符串是以空字符串作为结束符，一些图片中含有结束符，因此不是二进制安全的</code>。</li></ol></li></ul></li></ul></li></ul><p><a href=https://www.w3cschool.cn/hdclil/lun1dozt.html>https://www.w3cschool.cn/hdclil/lun1dozt.html</a></p><p>一致性，高可用这两个方面来弄。</p><ul><li><ol><li>redis基础知识</li></ol><ul><li>数据库的个数?<ul><li><ol><li>Redis默认有16个数据库；可以用SELECT来切换数据库；</li></ol></li><li><ol start=2><li>当redis-cli连上server，默认是0号数据库，个个数据库之间相互隔离，允许相同的key存在。</li></ol></li></ul></li><li>清空数据<ul><li>flushdb 清空当前数据库</li><li>flushall 清空所有数据库的数据</li></ul></li><li>CPU/MemeryIO/NetIO<ul><li>Redis是基于内存操作的，CPU不是Redis的性能瓶颈，Redis的瓶颈是根据机器的内存和网络带宽<ul><li>redis快的原因？<ul><li>redis所有的数据全部放在内存，是直接操作内存的。</li><li>它的瓶颈不是CPU，用单线程避免CPU上下文切换。</li><li>Redis是C语言写的。</li></ul></li></ul></li></ul></li></ul></li><li><ol start=2><li>redis五大类型，三种特殊类型</li></ol><ul><li>五<ul><li>string(字符串)</li><li>list(列表)</li><li>hash</li><li>set(集合)</li><li>zset(有序集合)</li></ul></li><li>三<ul><li>Geospatial(地理位置)</li><li>HyperLogLog(基数统计)</li><li>Bitmaps(位存储)</li></ul></li></ul></li><li><ol start=3><li><strong>Redis单条命令是保证原子性的，但是Redis的事务是不保证原子性的！</strong></li></ol><ul><li><strong>Redis事务没有隔离级别的概念。</strong></li><li><strong>Redis事务：</strong><ul><li><strong>开启事务(MULTI)</strong></li><li><strong>命令入队</strong><ul><li>如果命令入队的时候就错了（比如命令错了，命令参数错了），所有的都不会执行.</li></ul></li><li><strong>执行事务(EXEC)</strong><ul><li>但是执行的时候，出错了，拿它之前的命令已经是执行完毕了，不能够回滚。</li></ul></li><li>TODO / watch unwatch</li></ul></li></ul></li><li><ol start=4><li>redis持久化</li></ol><ul><li><p>RDB(Redis DataBase):</p><ul><li>what:<ul><li>RDB(Redis Database) 是通过快照(snapshot)的形式<strong>将数据保存到磁盘中</strong>。<ul><li>所谓快照，可以理解为在某一时间点将数据集拍照并保存下来。Redis 通过这种方式可以在指定的时间间隔或者执行特定命令时将当前系统中的数据保存备份，以二进制的形式写入磁盘中，默认文件名为dump.rdb。</li></ul></li></ul></li><li>why:<ul><li>使用RDB的优劣<ul><li>优势：<ul><li>文件格式的角度：RDB 是一个非常紧凑（compact）的文件（保存二进制数据），它保存了 Redis 在某个时间点上的数据集<ul><li>适合用于进行备份:比如说，你可以在最近的 24 小时内，每小时备份一次 RDB 文件，并且在每个月的每一天，也备份一个 RDB 文件。</li><li>非常适用于灾难恢复（disaster recovery）：它只有一个文件，并且内容都非常紧凑，可以（在加密后）将它传送到别的数据中心。</li></ul></li><li>保存的方式的角度：<ul><li>RDB 可以最大化 Redis 的性能：父进程在保存 RDB 文件时唯一要做的就是 fork 出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无须执行任何磁盘 I/O 操作；</li></ul></li></ul></li><li>劣势：<ul><li>发生故障停机， 就可能会丢失好几分钟的数据<ul><li>虽然 Redis 允许在设置不同的保存点（save point）来控制保存 RDB 文件的频率， 但是， 由于 RDB 文件需要保存整个数据集的状态， 所以这个过程并不快，可能会至少 5 分钟才能完成一次 RDB 文件保存</li></ul></li></ul></li></ul></li></ul></li><li>how:<ul><li>how it works?<ul><li>fork一个子进程<ul><li>Redis为了不阻塞线上业务，所以需要一边持久化一边响应客户端的请求，因此fork出一个子进程来处理这些保存工作。</li></ul></li><li>COW机制<ul><li>那么具体这个fork出来的子进程是如何做到使得Redis可以一边做持久化操作，一边做响应工作呢？这就涉及到COW (Copy On Write)机制。<ul><li>Redis在持久化的时候会去调用glibc的函数fork出一个子进程，快照持久化完成交由子进程来处理，父进程继续响应客户端的请求。而在子进程刚刚产生时，它其实使用的是父进程中的代码段和数据段。所以fork之后，kernel会将<strong>父进程</strong>中所有的内存页的权限都设置为read-only，然后子进程的地址空间指向父进程的地址空间。当父进程写内存时，CPU硬件检测到内存页是read-only的，就会触发页异常中断（page-fault），陷入 kernel 的一个中断例程。中断例程中，kernel就会把触发的异常的页复制一份，于是<strong>父子进程各自持有独立的一份</strong>。而此时子进程相应的数据还是没有发生变化，依旧是进程产生时那一瞬间的数据，故而子进程可以安心地遍历数据，进行序列化写入磁盘了。</li><li>随着父进程修改操作的持续进行，越来越多的共享页面将会被分离出来，内存就会持续增长，但是也不会超过原有数据内存的两倍大小（Redis实例里的冷数据占的比例往往是比较高的，所以很少出现所有页面都被分离的情况）。</li><li>COW机制的好处很明显：首先可以减少分配和复制时带来的瞬时延迟，还可以减少不必要的资源分配。但是缺点也很明显：如果父进程接收到大量的写操作，那么将会产生大量的分页错误（页异常中断page-fault）。</li></ul></li></ul></li></ul></li><li>how to use?<ul><li>save触发<ul><li>Redis是单线程程序，这个线程要同时负责多个客户端套接字的并发读写操作和内存结构的逻辑读写。而save命令会阻塞当前的Redis服务器，在执行该命令期间，Redis无法处理其他的命令，直到整个RDB过程完成为止，当这条指令执行完毕，将RDB文件保存下来后，才能继续去响应请求。这种方式用于新机器上数据的备份还好，如果用在生产上，那么简直是灾难，数据量过于庞大，阻塞的时间点过长。这种方式并不可取。</li></ul></li><li>bgsave触发<ul><li>为了不阻塞线上的业务，那么Redis就必须一边持久化，一边响应客户端的请求。所以在执行bgsave时可以通过fork一个子进程，然后通过这个子进程来处理接下来所有的保存工作，父进程就可以继续响应请求而无需去关心I/O操作。</li></ul></li><li>redis.config 配置<ul><li><code>save &lt;seconds> &lt;changes></code><ul><li>自动化的触发机制,使用bgsave</li></ul></li><li><code>save ""</code>禁止掉数据持久化</li></ul></li><li>执行shutdown命令关闭服务器时，如果没有开启AOF持久化功能，那么会自动执行一次bgsave</li><li>主从同步（slave和master建立同步机制）<ul><li><img src=https://raw.githubusercontent.com/zput/myPicLib/master/zput.github.io/20201210144331.png alt=20201210144331></li></ul></li></ul></li></ul></li></ul></li><li><p>AOF(Append Only File):</p><ul><li>what: AOF日志是持续增量的备份，是基于<strong>写命令</strong>存储的可读的文本文件。<ul><li>AOF日志:<ul><li>AOF只记录对内存进行修改的指令记录。</li><li>先执行指令<strong>再将日志存盘</strong>。</li><li>弱一致性。</li></ul></li></ul></li><li>why:<ul><li>为什么要有AOF：RDB 持久化是全量备份，比较耗时。</li><li>使用AOF的优劣<ul><li>优势：<ul><li>文件格式的角度：<ul><li>写入操作以 Redis 协议的格式保存， 因此 AOF 文件的内容非常容易被人读懂</li><li>AOF 文件是一个只进行追加操作的日志文件（append only log）， 因此对 AOF 文件的写入不需要进行 seek ， 即使日志因为某些原因而包含了未写入完整的命令（比如写入时磁盘已满，写入中途停机，等等）， redis-check-aof 工具也可以轻易地修复这种问题。</li><li>重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生停机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作。</li></ul></li><li>保存的方式的角度：<ul><li>AOF 持久化的默认策略为每秒钟 fsync 一次，在这种配置下，Redis 仍然可以保持良好的性能，并且就算发生故障停机，也最多也只会丢失掉一秒钟内的数据；</li></ul></li></ul></li><li>劣势：<ul><li>对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。</li><li>根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB。<ul><li>在一般情况下， 每秒fsync的性能依然非常高， 而关闭fsync可以让AOF的速度和RDB一样快，即使在高负荷之下也是如此。不过在处理巨大的写入载入时，RDB可以提供更有保证的最大延迟时间（latency）。</li></ul></li></ul></li></ul></li></ul></li><li>how:<ul><li>how to use?<ul><li>打开<code>appendonly yes</code>。</li><li><code>appendfsync always/everysec/no</code>默认是<code>appendfsync everysec</code>。<ul><li>always：每次发生数据修改就会立即记录到磁盘文件中，这种方案的完整性好但是IO开销很大，性能较差；</li><li>everysec：在每一秒中进行同步，速度有所提升。但是如果在一秒内宕机的话可能失去这一秒内的数据；<ul><li>再将AOF配置为appendfsync everysec之后，Redis在处理一条命令后，并不直接立即调用write将数据写入 AOF 文件，而是先将数据写入AOF buffer（server.aof_buf）。</li></ul></li><li>no：默认配置，即不使用 AOF 持久化方案。</li></ul></li><li>重写（rewrite）机制<ul><li>what:<strong>AOF Rewrite</strong>“压缩”AOF文件的过程<ul><li><strong>AOF Rewrite</strong>并非采用<strong>基于原AOF文件</strong>来重写或压缩，而是采取了类似RDB快照的方式：<ul><li>基于Copy On Write，全量遍历内存中数据，然后<strong>逐个序列</strong>到AOF文件中。因此AOF rewrite能够正确反应当前内存数据的状态。</li><li>重写过程中，对于新的变更操作将仍然被写入到原AOF文件中，同时这些新的变更操作也会被Redis收集起来。当内存中的数据被全部写入到新的AOF文件之后，收集的新的变更操作也将被一并追加到新的AOF文件中。然后将新AOF文件重命名为appendonly.aof，使用新AOF文件替换老文件，此后所有的操作都将被写入新的AOF文件。</li></ul></li></ul></li><li>why:AOF日志会在持续运行中持续增大，需要定期进行AOF重写，对AOF日志进行瘦身。<ul><li>fsync函数：配置为appendfsync everysec之后，Redis在处理一条命令后，并不直接立即调用write将数据写入 AOF 文件，而是先将数据写入AOF buffer（server.aof_buf）。调用write和命令处理是分开的，Redis只在每次进入epoll_wait之前做 write 操作。</li></ul></li><li>how:<ul><li>手动触发<ul><li><code>redis-cli -h ip -p port bgrewriteaof</code>。</li></ul></li><li>自动触发<ul><li>打开<code>no-appendfsync-on-rewrite yes</code>。</li><li><code>auto-aof-rewrite-min-size</code>:表示运行AOF重写时文件最小体积，默认为64MB（我们线上是512MB）。</li><li><code>auto-aof-rewrite-percentage</code>:代表当前AOF文件空间（aof_current_size）和上一次重写后AOF文件空间（aof_base_size）的值</li></ul></li></ul></li></ul></li></ul></li></ul></li></ul></li><li><p>Redis 4.0 混合持久化</p><ul><li>what: Redis 4.0引入。<ul><li>将 rdb 文件的内容和增量的 AOF 日志文件存在一起。这里的<strong>AOF 日志不再是全量</strong>的日志，而是自持久化开始到持久化结束的这段时间发生的<strong>增量 AOF</strong>日志，通常这部分 AOF 日志很小。相当于：<ul><li><img src=https://raw.githubusercontent.com/zput/myPicLib/master/zput.github.io/20201210172441.png alt=20201210172441></li><li>大量数据使用粗粒度（时间上）的rdb快照方式，性能高，恢复时间快。</li><li>增量数据使用细粒度（时间上）的AOF日志方式，尽量保证数据的不丢失。</li></ul></li></ul></li><li>why:<ul><li>仅使用RDB快照方式恢复数据，由于快照时间粒度较大，时回丢失大量数据。</li><li>仅使用AOF重放方式恢复数据，日志性能相对 rdb 来说要慢。在 Redis 实例很大的情况下，启动需要花费很长的时间。</li></ul></li><li>how:<ul><li>在 Redis 重启的时候，可以先加载 rdb 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，重启效率因此大幅得到提升。</li></ul></li><li>混合持久化是最佳方式吗？<ul><li>Master使用AOF，Slave使用RDB快照，master需要首先确保数据完整性，它作为数据备份的第一选择；slave提供只读服务或仅作为备机，它的主要目的就是快速响应客户端read请求或灾切换。</li></ul></li></ul></li></ul></li><li><ol start=5><li>高可用-高并发</li></ol><ul><li>主从复制是哨兵和集群能够实时的基础，因此主从复制是Redis高可用的基础！<ul><li>主从复制:<img src=https://raw.githubusercontent.com/zput/myPicLib/master/zput.github.io/20201210144331.png alt=20201210144331><ul><li>数据冗余:主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。</li><li>服务冗余:当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复。</li><li>负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，从节点提供读服务，分担服务器负载。</li></ul></li><li>哨兵(sentry)<ul><li><img src=https://raw.githubusercontent.com/zput/myPicLib/master/zput.github.io/20201210213656.png alt=哨兵模式 style=zoom:80%></li><li><strong>哨兵模式就是主从模式的升级，从手动到自动，更加健壮！</strong></li></ul></li><li>集群</li></ul></li></ul></li><li><ol start=6><li>缓存现象</li></ol><ul><li><p>6.1.缓存穿透(查不到)</p><ul><li>缓存层(N)-执行层(N); <strong>缓存层找不到，执行层也找不到</strong>，那么其实是浪费查询资源。</li><li><strong>single-key</strong><ul><li>what: 假设用户想要查询一个数据，发现Redis内存数据库没有，也就是缓存没有命中，于是向关系型数据库查询。发现关系型数据库中也没有，于是本次查询失败。当用户很多的时候，缓存都没有命中，于是请求都到了持久层数据库。这会给持久层数据库造成很大的压力。这时候就相当于出现了缓存穿透。</li><li>why:</li><li>how:<ul><li>how to solve?<ul><li><p>每次系统 A 从数据库中只要没查到，就写一个空值到缓存里去，比如 set -999 UNKNOWN。</p><ul><li>然后设置一个过期时间，这样的话，下次有相同的 key 来访问的时候，在缓存失效之前，都可以直接从缓存中取数据。</li></ul></li><li><p>redis布隆过滤器</p><ul><li><p>what:之前的布隆过滤器可以使用Redis中的位图操作实现，直到Redis4.0版本提供了插件功能，Redis官方提供的布隆过滤器才正式登场。布隆过滤器作为一个插件加载到Redis Server中，就会给Redis提供了强大的布隆去重功能。</p></li><li><p>why:</p></li><li><p>how:</p><ul><li>how to use?<ul><li>bf.add：添加元素到布隆过滤器中，类似于集合的sadd命令，不过bf.add命令只能一次添加一个元素，如果想一次添加多个元素，可以使用bf.madd命令。</li><li>bf.exists：判断某个元素是否在过滤器中，类似于集合的sismember命令，不过bf.exists命令只能一次查询一个元素，如果想一次查询多个元素，可以使用bf.mexists命令。</li><li>在使用bf.add命令添加元素之前，使用bf.reserve命令创建<strong>一个自定义的布隆过滤器</strong>。bf.reserve命令有三个参数，分别是：<ul><li>key：键</li><li>error_rate：期望错误率，期望错误率越低，需要的空间就越大。</li><li>capacity：初始容量，当实际元素的数量超过这个初始化容量时，误判率上升。<ul><li>布隆过滤器的error_rate越小，需要的存储空间就越大，对于不需要过于精确的场景，error_rate设置稍大一点也可以。布隆过滤器的capacity设置的过大，会浪费存储空间，设置的过小，就会影响准确率，所以在使用之前一定要尽可能地精确估计好元素数量，还需要加上一定的冗余空间以避免实际元素可能会意外高出设置值很多。总之，error_rate和 capacity都需要设置一个合适的数值。<ul><li><strong>默认的error_rate是 0.01，capacity是 100</strong></li></ul></li></ul></li></ul></li></ul></li></ul></li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1>#如果对应的key已经存在时，在执行bf.reserve命令就会报错。</span>
</span></span><span class=line><span class=cl><span class=c1>#如果不使用bf.reserve命令创建，而是使用Redis自动创建的布隆过滤器。</span>
</span></span><span class=line><span class=cl><span class=c1>#默认的error_rate是 0.01，capacity是 100。</span>
</span></span><span class=line><span class=cl>&gt; bf.reserve one-more-filter 0.0001 <span class=m>1000000</span> <span class=c1># 这个如果没有这一句，只有下面的，那么使用redis自动创建的不隆过滤器。</span>
</span></span><span class=line><span class=cl>OK
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>&gt; bf.add one-more-filter fans1
</span></span><span class=line><span class=cl><span class=o>(</span>integer<span class=o>)</span> <span class=m>1</span>
</span></span><span class=line><span class=cl>&gt; bf.add one-more-filter fans2
</span></span><span class=line><span class=cl><span class=o>(</span>integer<span class=o>)</span> <span class=m>1</span>
</span></span><span class=line><span class=cl>&gt; bf.add one-more-filter fans3
</span></span><span class=line><span class=cl><span class=o>(</span>integer<span class=o>)</span> <span class=m>1</span>
</span></span><span class=line><span class=cl>&gt; bf.exists one-more-filter fans1
</span></span><span class=line><span class=cl><span class=o>(</span>integer<span class=o>)</span> <span class=m>1</span>
</span></span><span class=line><span class=cl>&gt; bf.exists one-more-filter fans2
</span></span><span class=line><span class=cl><span class=o>(</span>integer<span class=o>)</span> <span class=m>1</span>
</span></span><span class=line><span class=cl>&gt; bf.exists one-more-filter fans3
</span></span><span class=line><span class=cl><span class=o>(</span>integer<span class=o>)</span> <span class=m>1</span>
</span></span><span class=line><span class=cl>&gt; bf.exists one-more-filter fans4
</span></span><span class=line><span class=cl><span class=o>(</span>integer<span class=o>)</span> <span class=m>0</span>
</span></span><span class=line><span class=cl>&gt; bf.madd one-more-filter fans4 fans5 fans6
</span></span><span class=line><span class=cl>1<span class=o>)</span> <span class=o>(</span>integer<span class=o>)</span> <span class=m>1</span>
</span></span><span class=line><span class=cl>2<span class=o>)</span> <span class=o>(</span>integer<span class=o>)</span> <span class=m>1</span>
</span></span><span class=line><span class=cl>3<span class=o>)</span> <span class=o>(</span>integer<span class=o>)</span> <span class=m>1</span>
</span></span><span class=line><span class=cl>&gt; bf.mexists one-more-filter fans4 fans5 fans6 fans7
</span></span><span class=line><span class=cl>1<span class=o>)</span> <span class=o>(</span>integer<span class=o>)</span> <span class=m>1</span>
</span></span><span class=line><span class=cl>2<span class=o>)</span> <span class=o>(</span>integer<span class=o>)</span> <span class=m>1</span>
</span></span><span class=line><span class=cl>3<span class=o>)</span> <span class=o>(</span>integer<span class=o>)</span> <span class=m>1</span>
</span></span><span class=line><span class=cl>4<span class=o>)</span> <span class=o>(</span>integer<span class=o>)</span> <span class=m>0</span>
</span></span></code></pre></td></tr></table></div></div></li></ul></li></ul></li></ul></li></ul></li><li><p>6.2.缓存击穿(高并发,缓存过期)</p><ul><li>缓存层(N)-执行层(Y)；<strong>缓存层找不到，执行层能找到</strong>，那么压力都在执行层里面。</li><li><strong>single-key</strong><ul><li>what:</li><li>why:</li><li>how:<ul><li>how to solve?<ul><li><strong>1.设置热点数据永不过期</strong><ul><li>从缓存层来看，没有设置过期时间，所以不会出现热点key过期后产生的问题。</li></ul></li><li><strong>2.加互斥锁</strong><ul><li>分布式锁：使用分布式锁，保证对于每个key同时只有一个线程去查询后端微服务，其他线程没有获得分布式锁的权限，因此只需要等待即可。这种方式将高并发的压力转移到了分布式锁，因此对分布式锁的考验极大。</li></ul></li></ul></li></ul></li></ul></li></ul></li><li><p>7.3.缓存雪崩(缓存集体失效)</p><ul><li>缓存层(N)-执行层(Y)；<strong>缓存层找不到，执行层能找到</strong>，但是很多key都有这种情况，是一段时间内一堆key都失效了，那么压力都在执行层里面。</li><li><strong>multi-key</strong><ul><li>what:</li><li>why:</li><li>how:<ul><li>how to solve?<ul><li>事前：redis 高可用，主从+哨兵，redis cluster，避免全盘崩溃。<ul><li><strong>Redis高可用</strong><ul><li>这个思想的含义是，既然Redis有可能挂掉，那么就多增加几台Redis服务器，这样一台服务器挂掉之后其他的还可以继续工作，其实就是搭建集群(异地多活)。</li></ul></li></ul></li><li>事中：本地 ehcache 缓存 + hystrix 限流&降级，避免 MySQL 被打死。<ul><li><strong>限流降级</strong><ul><li>SpringCloud的服务降级，SpringCloudAlibaba的服务限流。<ul><li>限流组件，可以设置每秒的请求，有多少能通过组件，剩余的未通过的请求，怎么办？<ul><li>走降级！可以返回一些默认的值，或者友情提示，或者空白的值。</li></ul></li></ul></li></ul></li></ul></li><li>事后：redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。<ul><li><strong>数据预热</strong><ul><li>在即将发生高并发访问前手动触发加载缓存不同的key，设置不同的过期时间，让缓存失效的时间尽量均匀！</li></ul></li></ul></li></ul></li></ul></li></ul></li></ul></li></ul></li></ul><p><a href=http://redisdoc.com/pubsub/index.html>redis api document</a></p><p><a href=https://zhuanlan.zhihu.com/p/82980434>面试题redis-缓存</a></p></div></div><div class=post-copyright><p class=copyright-item><span class=item-title>文章作者</span>
<span class=item-content>zput</span></p><p class=copyright-item><span class=item-title>上次更新</span>
<span class=item-content>0001-01-01</span></p></div><footer class=post-footer><nav class=post-nav><a class=prev href=/post/mrmk/mongo/><i class="iconfont icon-left"></i>
<span class="prev-text nav-default">mongo总结</span>
<span class="prev-text nav-mobile">上一篇</span></a></nav></footer></article></div><script src=https://giscus.app/client.js data-repo=zput/utterances-comments data-repo-id=R_kgDOHhATGQ data-category=Announcements data-category-id=DIC_kwDOHhATGc4CPxca data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=1 data-input-position=top data-theme=light data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script></div></main><footer id=footer class=footer><div class=social-links><a href=mailto:wkzxc@sina.com class="iconfont icon-email" title=email></a>
<a href=https://github.com/zput class="iconfont icon-github" title=github></a>
<a href=http://zput.github.io/index.xml type=application/rss+xml class="iconfont icon-rss" title=rss></a></div><div class=copyright><span class=copyright-year>&copy;
2017 -
2022<span class=heart><i class="iconfont icon-heart"></i></span><span>zput</span></span></div></footer><div class=back-to-top id=back-to-top><i class="iconfont icon-up"></i></div></div><script src=https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin=anonymous></script>
<script type=text/javascript src=/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js></script>
<script type=text/javascript>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><script async src=https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin=anonymous></script></body></html>