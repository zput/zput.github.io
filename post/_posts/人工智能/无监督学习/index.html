<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><title>无监督学习 - Zput's blog</title>
<meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=Cache-Control content="no-transform"><meta http-equiv=Cache-Control content="no-siteapp"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=author content="zput"><meta name=description content="无监督学习包含算法 聚类 K-means(K均值聚类) 降维 PCA 一家广告平台需要根据相似的人口学特征和购买习惯将美国人口分成不同的小组，以便广告客户"><meta name=keywords content="Hugo,theme,even"><meta name=generator content="Hugo 0.124.1 with theme even"><link rel=canonical href=http://zput.github.io/post/_posts/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/manifest.json><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link href=/sass/main.min.e291ec317bf4a8f48812dc8bcd749ad9270976917bf2027d01a4415caecb80a5.css rel=stylesheet><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin=anonymous><meta property="og:title" content="无监督学习"><meta property="og:description" content="无监督学习包含算法 聚类 K-means(K均值聚类) 降维 PCA 一家广告平台需要根据相似的人口学特征和购买习惯将美国人口分成不同的小组，以便广告客户"><meta property="og:type" content="article"><meta property="og:url" content="http://zput.github.io/post/_posts/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"><meta property="article:section" content="post"><meta property="article:published_time" content="2023-11-09T19:00:00+00:00"><meta property="article:modified_time" content="2023-11-09T19:00:00+00:00"><meta itemprop=name content="无监督学习"><meta itemprop=description content="无监督学习包含算法 聚类 K-means(K均值聚类) 降维 PCA 一家广告平台需要根据相似的人口学特征和购买习惯将美国人口分成不同的小组，以便广告客户"><meta itemprop=datePublished content="2023-11-09T19:00:00+00:00"><meta itemprop=dateModified content="2023-11-09T19:00:00+00:00"><meta itemprop=wordCount content="877"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="无监督学习"><meta name=twitter:description content="无监督学习包含算法 聚类 K-means(K均值聚类) 降维 PCA 一家广告平台需要根据相似的人口学特征和购买习惯将美国人口分成不同的小组，以便广告客户"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script><script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>Zput</a></div><div class=mobile-navbar-icon><span></span>
<span></span>
<span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><a href=/go-goroutine><li class=mobile-menu-item>go源码专栏</li></a><a href=/post/mrmk/><li class=mobile-menu-item>中间件专栏</li></a><a href=/post/cloud_native/><li class=mobile-menu-item>云原生专栏</li></a><a href=/post/postgraduate/><li class=mobile-menu-item>考研专栏</li></a><a href=/post/><li class=mobile-menu-item>时间线</li></a></ul></nav><div class=container id=mobile-panel><header id=header class=header><div class=logo-wrapper><a href=/ class=logo>Zput</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=/go-goroutine>go源码专栏</a></li><li class=menu-item><a class=menu-item-link href=/post/mrmk/>中间件专栏</a></li><li class=menu-item><a class=menu-item-link href=/post/cloud_native/>云原生专栏</a></li><li class=menu-item><a class=menu-item-link href=/post/postgraduate/>考研专栏</a></li><li class=menu-item><a class=menu-item-link href=/post/>时间线</a></li></ul></nav></header><main id=main class=main><div class=content-wrapper><div id=content class=content><article class=post><header class=post-header><h1 class=post-title>无监督学习</h1><div class=post-meta><span class=post-time>2023-11-09</span><div class=post-category><a href=/categories/applicationandsoftware/>applicationAndSoftware</a></div></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>文章目录</h2><div class="post-toc-content always-active"><nav id=TableOfContents><ul><li><ul><li><a href=#k-means算法>K-means算法</a><ul><li><a href=#api>API</a></li><li><a href=#性能评估指标>性能评估指标</a></li></ul></li></ul></li></ul></nav></div></div><div class=article-container><div class=post-content><p>无监督学习包含算法</p><ul><li><p>聚类</p><ul><li>K-means(K均值聚类)</li></ul></li><li><p>降维</p><ul><li>PCA</li></ul></li><li><p>一家广告平台需要根据相似的人口学特征和购买习惯将美国人口分成不同的小组，以便广告客户可以通过有关联的广告接触到他们的目标客户。</p></li><li><p>Airbnb需要将自己的房屋清单分组成不同的社区，以便用户能更轻松地查阅这些清单。</p></li><li><p>一个数据科学团队需要降低一个大型数据集的维度的数量，以便简化建模和降低文件大小。</p></li></ul><p>我们可以怎样最有用地对其进行归纳和分组？我们可以怎样以一种压缩格式有效地表
征数据？这都是无监督学习的目标，之所以称之为无监督，是因为这是从无标签的数
据开始学习的。</p><h2 id=k-means算法>K-means算法</h2><p>我们先来看一下一个K-means的聚类效果图</p><p align=middle><img src=https://raw.githubusercontent.com/zput/myPicLib/master/zput.github.io/20231129231440.png width=20% height=20% alt=效果图></p><p>K-means聚类步骤:</p><ol><li>随机设置K个特征空间内的点作为初始的聚类中心</li><li>对于其他每个点计算到K个中心的距离，未知的点选择最近的一个聚类中心点作为标记类别</li><li>接着对着标记的聚类中心之后，重新计算出每个聚类的新中心点（平均值）</li><li>如果计算得出的新中心点与原中心点一样，那么结束，否则重新进行第二步过程</li></ol><p align=middle><img src=https://raw.githubusercontent.com/zput/myPicLib/master/zput.github.io/20231129232338.png width=20% height=20% alt=效果图></p><h3 id=api>API</h3><ul><li><code>sklearn.cluster.KMeans(n_clusters=8,init='k-means++)</code><ul><li>k-means聚类</li><li>n_clusters:开始的聚类中心数量</li><li>init::初始化方法，默认为&rsquo;k-means++'</li><li>labels_:默认标记的类型，可以和真实值比较（不是值比较）</li></ul></li></ul><h3 id=性能评估指标>性能评估指标</h3><ol><li>轮廓系数</li></ol><p>$$
s c_{i}=\frac{b_{i-} a_{i}}{\max \left(b_{i}, a_{i}\right)}
$$</p><blockquote><p>注：对于每个点为已聚类数据中的样本，b1为到其它族群的所有样本的距离最小值，a为ⅰ到本身簇的距离平均值。最终计算出所有的样本点的轮廓系数平均值</p></blockquote><ol start=2><li>轮廓系数值分析</li></ol><p align=middle><img src=https://raw.githubusercontent.com/zput/myPicLib/master/zput.github.io/20231129232910.png width=20% height=20% alt=效果图></p><p>分析过程（我们以一个蓝1点为例）:</p><ol><li><p>计算出蓝1离本身族群所有点的距离的平均值ai</p></li><li><p>蓝1到其它两个族群的距离计算出平均值红平均，绿平均，取最小的那个距离作为bi</p></li><li><p>根据公式：极端值考虑：如果bi&#187;ai:那么公式结果趋近于1；如果ai&#187;>b_i:那么公式结果趋近于-1</p></li><li><p>结论</p></li></ol><p>如果 $b_i&#187;a_i$: 趋近于1效果越好，$b_i&#171;a_i$:趋近于-1，效果不好。轮廓系数的值是介于[-1,1]，越趋近于1代表内聚度和分离度都相对较优。</p><ol start=4><li>轮廓系数API</li></ol><ul><li><code>sklearn.metrics.silhouette_score(X,labels)</code><ul><li>计算所有样本的平均轮廓系数</li><li>X:特征值</li><li>labels:被聚类标记的目标值</li></ul></li></ul></div></div><div class=post-copyright><p class=copyright-item><span class=item-title>文章作者</span>
<span class=item-content>zput</span></p><p class=copyright-item><span class=item-title>上次更新</span>
<span class=item-content>2023-11-09</span></p></div><footer class=post-footer><nav class=post-nav><a class=next href=/post/_posts/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/><span class="next-text nav-default">线性回归和逻辑回归</span>
<span class="next-text nav-mobile">下一篇</span>
<i class="iconfont icon-right"></i></a></nav></footer></article></div><script src=https://giscus.app/client.js data-repo=zput/utterances-comments data-repo-id=R_kgDOHhATGQ data-category=Announcements data-category-id=DIC_kwDOHhATGc4CPxca data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=1 data-input-position=top data-theme=light data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script></div></main><footer id=footer class=footer><div class=social-links><a href=mailto:wkzxc@sina.com class="iconfont icon-email" title=email></a><a href=https://github.com/zput class="iconfont icon-github" title=github></a><a href=http://zput.github.io/index.xml type=application/rss+xml class="iconfont icon-rss" title=rss></a></div><div class=copyright><span class=copyright-year>&copy;
2017 -
2024<span class=heart><i class="iconfont icon-heart"></i></span><span>zput</span></span></div></footer><div class=back-to-top id=back-to-top><i class="iconfont icon-up"></i></div></div><script src=https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin=anonymous></script><script type=text/javascript src=/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js></script><script type=text/javascript>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><script async src=https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin=anonymous></script></body></html>